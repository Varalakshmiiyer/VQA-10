{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import Libraries for General Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tvnguyen/Softwares/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "/Users/tvnguyen/Softwares/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg') \n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "import ujson as json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# look at dataset\n",
    "from imp import reload\n",
    "import image_grid\n",
    "reload(image_grid)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries for Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import spacy.en\n",
    "#from spacy.strings import StringStore, hash_string\n",
    "\n",
    "import snowballstemmer\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    ")\n",
    "\n",
    "#from cross_validation import cross_val_apply\n",
    "#from stacked_classifier import StackedClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading VQA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_captions(caption_dir, section):\n",
    "    ans = 'captions_%s2014.json' % section\n",
    "    with (caption_dir / ans).open() as file_:\n",
    "        ans_data = json.load(file_)\n",
    "    caption_by_id = {}\n",
    "    for answer in ans_data['annotations']:\n",
    "        image = str(answer['image_id'])\n",
    "        caption = answer['caption']\n",
    "        caption_by_id[image] = str(caption)\n",
    "    return caption_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_captions = read_captions(Path('../Train'), 'train')\n",
    "eval_captions = read_captions(Path('../Val'), 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A crowd of people holding umbrellas walk in a plaza.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_captions['4576']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reading_vqa_data(vqa_dir, section, captions):\n",
    "    ans = 'mscoco_%s2014_annotations.json' % section\n",
    "    with (vqa_dir / ans).open() as file_:\n",
    "        ans_data = json.load(file_)\n",
    "    caption_by_id = {}\n",
    "    answers_by_id = {}\n",
    "    for answer in ans_data['annotations']:\n",
    "        image = str(answer['image_id'])\n",
    "        mca = answer['multiple_choice_answer']\n",
    "        caption = captions[image]\n",
    "        caption_by_id[answer['question_id']] = caption\n",
    "        answers_by_id[answer['question_id']] = mca\n",
    "    filename = ('MultipleChoice_mscoco_'\n",
    "                '%s2014_questions.json' % section)\n",
    "    with (vqa_dir / filename).open() as file_:\n",
    "        ques_data = json.load(file_)\n",
    "    for question in ques_data['questions']:\n",
    "        text = question['question']\n",
    "        ques_id = question['question_id']\n",
    "        options = question['multiple_choices']\n",
    "        image_path = caption_by_id[ques_id]\n",
    "        yield ques_id, caption_by_id[ques_id], text, options, answers_by_id[ques_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "train_data = list(reading_vqa_data(Path('Train'), 'train', train_captions))\n",
    "eval_data = list(reading_vqa_data(Path('Val'), 'val', eval_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_answers(data, top_n=1000):\n",
    "    freqs = Counter()\n",
    "    ans2id = {}\n",
    "    id2ans = {}\n",
    "    ans2ques = {}\n",
    "    id2ques = {}\n",
    "    for ques_id, _, _2, _3, answer in data:\n",
    "        freqs[answer] += 1\n",
    "        ans2ques[answer] = ques_id\n",
    "    most_common = freqs.most_common(top_n)\n",
    "    #most_common = freqs.most_common()\n",
    "    for i, (string, _) in enumerate(most_common):\n",
    "        ans2id[string] = i+1\n",
    "        id2ans[i+1] = string\n",
    "        id2ques[i+1] = ans2ques[string]\n",
    "    return ans2id, id2ans, id2ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top_n = 16140\n",
    "top_n = 5000\n",
    "ans2id, id2ans, id2ques = get_answers(train_data, top_n)\n",
    "most_common_a = id2ans[1]\n",
    "most_common_q = id2ques[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_answers(data):\n",
    "    image_files = {}\n",
    "    for ques_id, image_path, text, opt, answer in data:\n",
    "        #if exclude_missing and answer not in answers:\n",
    "        if answer not in ans2id:\n",
    "            ans2id[answer] = 0\n",
    "            id2ans[0] = most_common_a\n",
    "            id2ques[0] = most_common_q\n",
    "        idx = ans2id[answer]\n",
    "        image_paths = image_files.get(idx)\n",
    "        if (image_paths == None):\n",
    "            image_paths = []\n",
    "        image_paths.append((image_path))\n",
    "        image_files[idx] = image_paths\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_answers(data, exclude_missing=False):\n",
    "    encoded = []\n",
    "    for ques_id, caption, text, opt_ans, answer in data:\n",
    "        for a in opt_ans:\n",
    "            if a not in ans2id:\n",
    "                ans2id[a] = 0\n",
    "                id2ans[0] = most_common_a\n",
    "                id2ques[0] = most_common_q\n",
    "        opt = [ans2id[a] for a in opt_ans]\n",
    "        encoded.append((ques_id, caption, text, opt_ans, opt, answer, ans2id.get(answer, 0)))\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_images = image_answers(train_data)\n",
    "train_data = encode_answers(train_data)\n",
    "eval_images = image_answers(eval_data)\n",
    "eval_data = encode_answers(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248349 121512\n"
     ]
    }
   ],
   "source": [
    "n_train = 0\n",
    "n_eval = 0\n",
    "for answer in training_images:\n",
    "    n_train = n_train + len(training_images[answer])\n",
    "for answer in eval_images:\n",
    "    n_eval = n_eval + len(eval_images[answer])\n",
    "\n",
    "print(n_train, n_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = [q[2] for q in train_data]\n",
    "X_te = [q[2] for q in eval_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = [q[6] for q in train_data]\n",
    "y_te = [q[6] for q in eval_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248349, 248349, 121512, 121512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_tr), len(y_tr), len(X_te), len(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the table made of?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_te[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'shape', 'is', 'the', 'bench', 'seat']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_vect = CountVectorizer(ngram_range=(1, 1), lowercase=False, token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "unigram_analyze = unigram_vect.build_analyzer()\n",
    "unigram_analyze(X_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tags_st(tks):\n",
    "    return ' '.join([w[1] for w in tks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class POSTags(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        tokens = [unigram_analyze(row) for row in x]\n",
    "        self.tags = [nltk.pos_tag(row) for row in tokens]\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return [tags_st(row) for row in self.tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger = POSTags()\n",
    "tags = tagger.fit_transform(X_tr[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What shape is the bench seat?',\n",
       " 'Is there a shadow?',\n",
       " 'Is this one bench or multiple benches?',\n",
       " 'Is this a modern train?',\n",
       " 'What color is the stripe on the train?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WP NN VBZ DT JJ NN',\n",
       " 'VBZ EX DT NN',\n",
       " 'VBZ DT CD NN CC JJ NNS',\n",
       " 'VBZ DT DT JJ NN',\n",
       " 'WP NN VBZ DT NN IN DT NN']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer for feature extraction\n",
    "    the sentence itself --> unigrams and bi-grams features\n",
    "    the sentence in lowercase --> unigrams and bi-grams features\n",
    "    the sentence pos-tags --> unigrams and bi-grams features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_features_1 = FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling words features - lowercased\n",
    "            ('lower_count', TfidfVectorizer(ngram_range=(1, 1),\n",
    "                                                token_pattern=r'\\b\\w+\\b', min_df=1, stop_words='english')),\n",
    "\n",
    "            # Pipeline for pulling POS-Tag features\n",
    "            ('tags', Pipeline([\n",
    "                ('postag', POSTags()),\n",
    "                ('pos_vect', TfidfVectorizer(ngram_range=(1, 1), lowercase=False,\n",
    "                                                token_pattern=r'\\b\\w+\\b', min_df=1, stop_words='english')),\n",
    "            ])),\n",
    "\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_features_2 = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            # Pipeline for pulling words features - lowercased\n",
    "            ('lower_count', TfidfVectorizer(ngram_range=(1, 2),\n",
    "                                                token_pattern=r'\\b\\w+\\b', min_df=1, stop_words='english')),\n",
    "\n",
    "            # Pipeline for pulling POS-Tag features\n",
    "            ('tags', Pipeline([\n",
    "                ('postag', POSTags()),\n",
    "                ('pos_vect', TfidfVectorizer(ngram_range=(1, 2), lowercase=False,\n",
    "                                                token_pattern=r'\\b\\w+\\b', min_df=1, stop_words='english')),\n",
    "            ])),\n",
    "\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = list(X_tr + X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248349"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ngrams = combined_features_1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369861, 15035)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr_ngrams = X_ngrams[0:248349]\n",
    "X_te_ngrams = X_ngrams[248349:369861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((248349, 15035), (121512, 15035))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_ngrams.shape, X_te_ngrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.28146273,  0.33134329,  0.45001303,  0.53554135,\n",
       "        0.53991662,  0.56716319,  0.56806144,  0.62112498])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = X_tr_ngrams.getrow(0).todense()[0]\n",
    "a = list(np.array(a).reshape(-1,))\n",
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training with Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc.fit(X_tr_ngrams, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = 30000\n",
    "rfc.fit(X_tr_ngrams[start:], y_tr[start:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = X_te_ngrams[0:30000]\n",
    "X2 = X_te_ngrams[30000:60000]\n",
    "X3 = X_te_ngrams[60000:90000]\n",
    "X4 = X_te_ngrams[90000:121512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_eval_1 = rfc.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_eval_2 = rfc.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_eval_3 = rfc.predict(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_eval_4 = rfc.predict(X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_eval = np.concatenate([y_eval_1, y_eval_2, y_eval_3, y_eval_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_eval).to_csv(\"predictions.csv\", header = False, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = []\n",
    "i = 0\n",
    "for ques_id, _, _2, _3, _4, _5, _6 in eval_data:\n",
    "    a = id2ans[y_eval[i]]\n",
    "    d = {'answer' : a, 'question_id': ques_id}\n",
    "    r.append(d)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('results_text.json', 'w') as f:\n",
    "    json.dump(r, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
